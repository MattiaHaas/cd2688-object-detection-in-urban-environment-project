023-12-08 09:35:11 Training - Training image download completed. Training in progress...2023-12-08 09:35:26,992 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)
2023-12-08 09:35:27,030 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)
2023-12-08 09:35:27,069 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)
2023-12-08 09:35:27,081 sagemaker-training-toolkit INFO     Invoking user script
Training Env:
{
    "additional_framework_parameters": {},
    "channel_input_dirs": {
        "train": "/opt/ml/input/data/train",
        "val": "/opt/ml/input/data/val"
    },
    "current_host": "algo-1",
    "current_instance_group": "homogeneousCluster",
    "current_instance_group_hosts": [
        "algo-1"
    ],
    "current_instance_type": "ml.g5.xlarge",
    "distribution_hosts": [],
    "distribution_instance_groups": [],
    "framework_module": null,
    "hosts": [
        "algo-1"
    ],
    "hyperparameters": {
        "model_dir": "/opt/training",
        "num_train_steps": "2000",
        "pipeline_config_path": "pipeline.config",
        "sample_1_of_n_eval_examples": "1"
    },
    "input_config_dir": "/opt/ml/input/config",
    "input_data_config": {
        "train": {
            "TrainingInputMode": "File",
            "S3DistributionType": "FullyReplicated",
            "RecordWrapperType": "None"
        },
        "val": {
            "TrainingInputMode": "File",
            "S3DistributionType": "FullyReplicated",
            "RecordWrapperType": "None"
        }
    },
    "input_dir": "/opt/ml/input",
    "instance_groups": [
        "homogeneousCluster"
    ],
    "instance_groups_dict": {
        "homogeneousCluster": {
            "instance_group_name": "homogeneousCluster",
            "instance_type": "ml.g5.xlarge",
            "hosts": [
                "algo-1"
            ]
        }
    },
    "is_hetero": false,
    "is_master": true,
    "is_modelparallel_enabled": null,
    "is_smddpmprun_installed": false,
    "is_smddprun_installed": false,
    "job_name": "tf2-object-detection-2023-12-08-09-31-21-450",
    "log_level": 20,
    "master_hostname": "algo-1",
    "model_dir": "/opt/ml/model",
    "module_dir": "s3://sagemaker-us-east-1-521625590017/tf2-object-detection-2023-12-08-09-31-21-450/source/sourcedir.tar.gz",
    "module_name": "run_training.sh",
    "network_interface_name": "eth0",
    "num_cpus": 4,
    "num_gpus": 1,
    "num_neurons": 0,
    "output_data_dir": "/opt/ml/output/data",
    "output_dir": "/opt/ml/output",
    "output_intermediate_dir": "/opt/ml/output/intermediate",
    "resource_config": {
        "current_host": "algo-1",
        "current_instance_type": "ml.g5.xlarge",
        "current_group_name": "homogeneousCluster",
        "hosts": [
            "algo-1"
        ],
        "instance_groups": [
            {
                "instance_group_name": "homogeneousCluster",
                "instance_type": "ml.g5.xlarge",
                "hosts": [
                    "algo-1"
                ]
            }
        ],
        "network_interface_name": "eth0"
    },
    "user_entry_point": "run_training.sh"
}
Environment variables:
SM_HOSTS=["algo-1"]
SM_NETWORK_INTERFACE_NAME=eth0
SM_HPS={"model_dir":"/opt/training","num_train_steps":"2000","pipeline_config_path":"pipeline.config","sample_1_of_n_eval_examples":"1"}
SM_USER_ENTRY_POINT=run_training.sh
SM_FRAMEWORK_PARAMS={}
SM_RESOURCE_CONFIG={"current_group_name":"homogeneousCluster","current_host":"algo-1","current_instance_type":"ml.g5.xlarge","hosts":["algo-1"],"instance_groups":[{"hosts":["algo-1"],"instance_group_name":"homogeneousCluster","instance_type":"ml.g5.xlarge"}],"network_interface_name":"eth0"}
SM_INPUT_DATA_CONFIG={"train":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"},"val":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}}
SM_OUTPUT_DATA_DIR=/opt/ml/output/data
SM_CHANNELS=["train","val"]
SM_CURRENT_HOST=algo-1
SM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge
SM_CURRENT_INSTANCE_GROUP=homogeneousCluster
SM_CURRENT_INSTANCE_GROUP_HOSTS=["algo-1"]
SM_INSTANCE_GROUPS=["homogeneousCluster"]
SM_INSTANCE_GROUPS_DICT={"homogeneousCluster":{"hosts":["algo-1"],"instance_group_name":"homogeneousCluster","instance_type":"ml.g5.xlarge"}}
SM_DISTRIBUTION_INSTANCE_GROUPS=[]
SM_IS_HETERO=false
SM_MODULE_NAME=run_training.sh
SM_LOG_LEVEL=20
SM_FRAMEWORK_MODULE=
SM_INPUT_DIR=/opt/ml/input
SM_INPUT_CONFIG_DIR=/opt/ml/input/config
SM_OUTPUT_DIR=/opt/ml/output
SM_NUM_CPUS=4
SM_NUM_GPUS=1
SM_NUM_NEURONS=0
SM_MODEL_DIR=/opt/ml/model
SM_MODULE_DIR=s3://sagemaker-us-east-1-521625590017/tf2-object-detection-2023-12-08-09-31-21-450/source/sourcedir.tar.gz
SM_TRAINING_ENV={"additional_framework_parameters":{},"channel_input_dirs":{"train":"/opt/ml/input/data/train","val":"/opt/ml/input/data/val"},"current_host":"algo-1","current_instance_group":"homogeneousCluster","current_instance_group_hosts":["algo-1"],"current_instance_type":"ml.g5.xlarge","distribution_hosts":[],"distribution_instance_groups":[],"framework_module":null,"hosts":["algo-1"],"hyperparameters":{"model_dir":"/opt/training","num_train_steps":"2000","pipeline_config_path":"pipeline.config","sample_1_of_n_eval_examples":"1"},"input_config_dir":"/opt/ml/input/config","input_data_config":{"train":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"},"val":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}},"input_dir":"/opt/ml/input","instance_groups":["homogeneousCluster"],"instance_groups_dict":{"homogeneousCluster":{"hosts":["algo-1"],"instance_group_name":"homogeneousCluster","instance_type":"ml.g5.xlarge"}},"is_hetero":false,"is_master":true,"is_modelparallel_enabled":null,"is_smddpmprun_installed":false,"is_smddprun_installed":false,"job_name":"tf2-object-detection-2023-12-08-09-31-21-450","log_level":20,"master_hostname":"algo-1","model_dir":"/opt/ml/model","module_dir":"s3://sagemaker-us-east-1-521625590017/tf2-object-detection-2023-12-08-09-31-21-450/source/sourcedir.tar.gz","module_name":"run_training.sh","network_interface_name":"eth0","num_cpus":4,"num_gpus":1,"num_neurons":0,"output_data_dir":"/opt/ml/output/data","output_dir":"/opt/ml/output","output_intermediate_dir":"/opt/ml/output/intermediate","resource_config":{"current_group_name":"homogeneousCluster","current_host":"algo-1","current_instance_type":"ml.g5.xlarge","hosts":["algo-1"],"instance_groups":[{"hosts":["algo-1"],"instance_group_name":"homogeneousCluster","instance_type":"ml.g5.xlarge"}],"network_interface_name":"eth0"},"user_entry_point":"run_training.sh"}
SM_USER_ARGS=["--model_dir","/opt/training","--num_train_steps","2000","--pipeline_config_path","pipeline.config","--sample_1_of_n_eval_examples","1"]
SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate
SM_CHANNEL_TRAIN=/opt/ml/input/data/train
SM_CHANNEL_VAL=/opt/ml/input/data/val
SM_HP_MODEL_DIR=/opt/training
SM_HP_NUM_TRAIN_STEPS=2000
SM_HP_PIPELINE_CONFIG_PATH=pipeline.config
SM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1
PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages
Invoking script with the following command:
/bin/sh -c "./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1"
2023-12-08 09:35:27,082 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.
===TRAINING THE MODEL==
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I1208 09:35:32.601654 140351250462528 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: 2000
I1208 09:35:32.796211 140351250462528 config_util.py:552] Maybe overwriting train_steps: 2000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I1208 09:35:32.796370 140351250462528 config_util.py:552] Maybe overwriting use_bfloat16: False
I1208 09:35:32.804939 140351250462528 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1
I1208 09:35:32.805034 140351250462528 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88
I1208 09:35:32.805105 140351250462528 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4
I1208 09:35:32.809084 140351250462528 efficientnet_model.py:143] round_filter input=32 output=32
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.821469 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.824935 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.830185 140351250462528 efficientnet_model.py:143] round_filter input=32 output=32
I1208 09:35:33.830265 140351250462528 efficientnet_model.py:143] round_filter input=16 output=16
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.848727 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.851163 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.906871 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.909348 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.931369 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.933776 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.986164 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.988605 140351250462528 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1208 09:35:33.997326 140351250462528 efficientnet_model.py:143] round_filter input=16 output=16
I1208 09:35:33.997412 140351250462528 efficientnet_model.py:143] round_filter input=24 output=24
I1208 09:35:34.302527 140351250462528 efficientnet_model.py:143] round_filter input=24 output=24
I1208 09:35:34.302653 140351250462528 efficientnet_model.py:143] round_filter input=40 output=40
I1208 09:35:34.606484 140351250462528 efficientnet_model.py:143] round_filter input=40 output=40
I1208 09:35:34.606606 140351250462528 efficientnet_model.py:143] round_filter input=80 output=80
I1208 09:35:35.000641 140351250462528 efficientnet_model.py:143] round_filter input=80 output=80
I1208 09:35:35.000769 140351250462528 efficientnet_model.py:143] round_filter input=112 output=112
I1208 09:35:35.396505 140351250462528 efficientnet_model.py:143] round_filter input=112 output=112
I1208 09:35:35.396637 140351250462528 efficientnet_model.py:143] round_filter input=192 output=192
I1208 09:35:35.896040 140351250462528 efficientnet_model.py:143] round_filter input=192 output=192
I1208 09:35:35.896167 140351250462528 efficientnet_model.py:143] round_filter input=320 output=320
I1208 09:35:36.102259 140351250462528 efficientnet_model.py:143] round_filter input=1280 output=1280
I1208 09:35:36.188514 140351250462528 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W1208 09:35:36.368589 140351250462528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']
I1208 09:35:36.374910 140351250462528 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']
INFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']
I1208 09:35:36.375948 140351250462528 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']
INFO:tensorflow:Number of filenames to read: 84
I1208 09:35:36.376033 140351250462528 dataset_builder.py:80] Number of filenames to read: 84
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
W1208 09:35:36.381919 140351250462528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W1208 09:35:36.396218 140351250462528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W1208 09:35:42.744843 140351250462528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1208 09:35:46.348129 140351250462528 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn(
I1208 09:35:55.279325 140322949064448 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
I1208 09:36:05.051935 140322949064448 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W1208 09:36:16.554785 140345454868224 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
I1208 09:36:18.937036 140345454868224 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
W1208 09:36:24.527448 140345454868224 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
I1208 09:36:29.499203 140345454868224 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
W1208 09:36:34.991663 140345454868224 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
I1208 09:36:39.154252 140345454868224 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
W1208 09:36:44.688589 140345454868224 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
I1208 09:36:49.021349 140345454868224 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
W1208 09:36:55.042721 140345454868224 utils.py:82] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
INFO:tensorflow:Step 100 per-step time 1.326s
I1208 09:38:28.969035 140351250462528 model_lib_v2.py:705] Step 100 per-step time 1.326s
INFO:tensorflow:{'Loss/classification_loss': 0.42772773,
 'Loss/localization_loss': 0.042750176,
 'Loss/regularization_loss': 0.029542627,
 'Loss/total_loss': 0.50002056,
 'learning_rate': 0.00416}
I1208 09:38:28.969331 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.42772773,
 'Loss/localization_loss': 0.042750176,
 'Loss/regularization_loss': 0.029542627,
 'Loss/total_loss': 0.50002056,
 'learning_rate': 0.00416}
INFO:tensorflow:Step 200 per-step time 0.661s
I1208 09:39:34.949974 140351250462528 model_lib_v2.py:705] Step 200 per-step time 0.661s
INFO:tensorflow:{'Loss/classification_loss': 0.33795387,
 'Loss/localization_loss': 0.026962169,
 'Loss/regularization_loss': 0.029545475,
 'Loss/total_loss': 0.3944615,
 'learning_rate': 0.0073200003}
I1208 09:39:34.950232 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.33795387,
 'Loss/localization_loss': 0.026962169,
 'Loss/regularization_loss': 0.029545475,
 'Loss/total_loss': 0.3944615,
 'learning_rate': 0.0073200003}
INFO:tensorflow:Step 300 per-step time 0.659s
I1208 09:40:40.880487 140351250462528 model_lib_v2.py:705] Step 300 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.3301781,
 'Loss/localization_loss': 0.018119045,
 'Loss/regularization_loss': 0.02954776,
 'Loss/total_loss': 0.3778449,
 'learning_rate': 0.010480001}
I1208 09:40:40.880740 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.3301781,
 'Loss/localization_loss': 0.018119045,
 'Loss/regularization_loss': 0.02954776,
 'Loss/total_loss': 0.3778449,
 'learning_rate': 0.010480001}
INFO:tensorflow:Step 400 per-step time 0.658s
I1208 09:41:46.683681 140351250462528 model_lib_v2.py:705] Step 400 per-step time 0.658s
INFO:tensorflow:{'Loss/classification_loss': 0.40385127,
 'Loss/localization_loss': 0.024845978,
 'Loss/regularization_loss': 0.029551217,
 'Loss/total_loss': 0.45824847,
 'learning_rate': 0.0136400005}
I1208 09:41:46.683929 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.40385127,
 'Loss/localization_loss': 0.024845978,
 'Loss/regularization_loss': 0.029551217,
 'Loss/total_loss': 0.45824847,
 'learning_rate': 0.0136400005}
INFO:tensorflow:Step 500 per-step time 0.660s
I1208 09:42:52.667622 140351250462528 model_lib_v2.py:705] Step 500 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.36415413,
 'Loss/localization_loss': 0.022136988,
 'Loss/regularization_loss': 0.029564181,
 'Loss/total_loss': 0.4158553,
 'learning_rate': 0.016800001}
I1208 09:42:52.667880 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.36415413,
 'Loss/localization_loss': 0.022136988,
 'Loss/regularization_loss': 0.029564181,
 'Loss/total_loss': 0.4158553,
 'learning_rate': 0.016800001}
INFO:tensorflow:Step 600 per-step time 0.660s
I1208 09:43:58.619421 140351250462528 model_lib_v2.py:705] Step 600 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.23988682,
 'Loss/localization_loss': 0.0130011225,
 'Loss/regularization_loss': 0.02958366,
 'Loss/total_loss': 0.2824716,
 'learning_rate': 0.019960001}
I1208 09:43:58.619676 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.23988682,
 'Loss/localization_loss': 0.0130011225,
 'Loss/regularization_loss': 0.02958366,
 'Loss/total_loss': 0.2824716,
 'learning_rate': 0.019960001}
INFO:tensorflow:Step 700 per-step time 0.660s
I1208 09:45:04.669407 140351250462528 model_lib_v2.py:705] Step 700 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.27208936,
 'Loss/localization_loss': 0.01639538,
 'Loss/regularization_loss': 0.029599942,
 'Loss/total_loss': 0.3180847,
 'learning_rate': 0.023120001}
I1208 09:45:04.669647 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.27208936,
 'Loss/localization_loss': 0.01639538,
 'Loss/regularization_loss': 0.029599942,
 'Loss/total_loss': 0.3180847,
 'learning_rate': 0.023120001}
INFO:tensorflow:Step 800 per-step time 0.658s
I1208 09:46:10.484839 140351250462528 model_lib_v2.py:705] Step 800 per-step time 0.658s
INFO:tensorflow:{'Loss/classification_loss': 0.3408435,
 'Loss/localization_loss': 0.020247683,
 'Loss/regularization_loss': 0.02963298,
 'Loss/total_loss': 0.39072418,
 'learning_rate': 0.02628}
I1208 09:46:10.485068 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.3408435,
 'Loss/localization_loss': 0.020247683,
 'Loss/regularization_loss': 0.02963298,
 'Loss/total_loss': 0.39072418,
 'learning_rate': 0.02628}
INFO:tensorflow:Step 900 per-step time 0.659s
I1208 09:47:16.337018 140351250462528 model_lib_v2.py:705] Step 900 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.33654368,
 'Loss/localization_loss': 0.022142166,
 'Loss/regularization_loss': 0.029662993,
 'Loss/total_loss': 0.38834885,
 'learning_rate': 0.02944}
I1208 09:47:16.337249 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.33654368,
 'Loss/localization_loss': 0.022142166,
 'Loss/regularization_loss': 0.029662993,
 'Loss/total_loss': 0.38834885,
 'learning_rate': 0.02944}
INFO:tensorflow:Step 1000 per-step time 0.659s
I1208 09:48:22.285659 140351250462528 model_lib_v2.py:705] Step 1000 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.2970673,
 'Loss/localization_loss': 0.024383677,
 'Loss/regularization_loss': 0.029693961,
 'Loss/total_loss': 0.35114494,
 'learning_rate': 0.0326}
I1208 09:48:22.285903 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2970673,
 'Loss/localization_loss': 0.024383677,
 'Loss/regularization_loss': 0.029693961,
 'Loss/total_loss': 0.35114494,
 'learning_rate': 0.0326}
INFO:tensorflow:Step 1100 per-step time 0.677s
I1208 09:49:29.983719 140351250462528 model_lib_v2.py:705] Step 1100 per-step time 0.677s
INFO:tensorflow:{'Loss/classification_loss': 0.23423848,
 'Loss/localization_loss': 0.011509096,
 'Loss/regularization_loss': 0.029742649,
 'Loss/total_loss': 0.27549022,
 'learning_rate': 0.03576}
I1208 09:49:29.983972 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.23423848,
 'Loss/localization_loss': 0.011509096,
 'Loss/regularization_loss': 0.029742649,
 'Loss/total_loss': 0.27549022,
 'learning_rate': 0.03576}
INFO:tensorflow:Step 1200 per-step time 0.660s
I1208 09:50:36.003345 140351250462528 model_lib_v2.py:705] Step 1200 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.22275636,
 'Loss/localization_loss': 0.010303889,
 'Loss/regularization_loss': 0.029821025,
 'Loss/total_loss': 0.26288128,
 'learning_rate': 0.03892}
I1208 09:50:36.003595 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.22275636,
 'Loss/localization_loss': 0.010303889,
 'Loss/regularization_loss': 0.029821025,
 'Loss/total_loss': 0.26288128,
 'learning_rate': 0.03892}
INFO:tensorflow:Step 1300 per-step time 0.659s
I1208 09:51:41.856682 140351250462528 model_lib_v2.py:705] Step 1300 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.2393808,
 'Loss/localization_loss': 0.009589064,
 'Loss/regularization_loss': 0.029896684,
 'Loss/total_loss': 0.27886656,
 'learning_rate': 0.04208}
I1208 09:51:41.856916 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2393808,
 'Loss/localization_loss': 0.009589064,
 'Loss/regularization_loss': 0.029896684,
 'Loss/total_loss': 0.27886656,
 'learning_rate': 0.04208}
INFO:tensorflow:Step 1400 per-step time 0.658s
I1208 09:52:47.701016 140351250462528 model_lib_v2.py:705] Step 1400 per-step time 0.658s
INFO:tensorflow:{'Loss/classification_loss': 0.29404795,
 'Loss/localization_loss': 0.015301334,
 'Loss/regularization_loss': 0.029945832,
 'Loss/total_loss': 0.33929512,
 'learning_rate': 0.04524}
I1208 09:52:47.701256 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.29404795,
 'Loss/localization_loss': 0.015301334,
 'Loss/regularization_loss': 0.029945832,
 'Loss/total_loss': 0.33929512,
 'learning_rate': 0.04524}
INFO:tensorflow:Step 1500 per-step time 0.658s
I1208 09:53:53.500735 140351250462528 model_lib_v2.py:705] Step 1500 per-step time 0.658s
INFO:tensorflow:{'Loss/classification_loss': 0.23080625,
 'Loss/localization_loss': 0.00944119,
 'Loss/regularization_loss': 0.030015407,
 'Loss/total_loss': 0.27026284,
 'learning_rate': 0.0484}
I1208 09:53:53.500993 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.23080625,
 'Loss/localization_loss': 0.00944119,
 'Loss/regularization_loss': 0.030015407,
 'Loss/total_loss': 0.27026284,
 'learning_rate': 0.0484}
INFO:tensorflow:Step 1600 per-step time 0.659s
I1208 09:54:59.372940 140351250462528 model_lib_v2.py:705] Step 1600 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.2472345,
 'Loss/localization_loss': 0.012443718,
 'Loss/regularization_loss': 0.030120138,
 'Loss/total_loss': 0.28979835,
 'learning_rate': 0.05156}
I1208 09:54:59.373180 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.2472345,
 'Loss/localization_loss': 0.012443718,
 'Loss/regularization_loss': 0.030120138,
 'Loss/total_loss': 0.28979835,
 'learning_rate': 0.05156}
INFO:tensorflow:Step 1700 per-step time 0.659s
I1208 09:56:05.310055 140351250462528 model_lib_v2.py:705] Step 1700 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.31851462,
 'Loss/localization_loss': 0.016571024,
 'Loss/regularization_loss': 0.03025399,
 'Loss/total_loss': 0.3653396,
 'learning_rate': 0.05472}
I1208 09:56:05.310292 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.31851462,
 'Loss/localization_loss': 0.016571024,
 'Loss/regularization_loss': 0.03025399,
 'Loss/total_loss': 0.3653396,
 'learning_rate': 0.05472}
INFO:tensorflow:Step 1800 per-step time 0.660s
I1208 09:57:11.268540 140351250462528 model_lib_v2.py:705] Step 1800 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.27975702,
 'Loss/localization_loss': 0.021239476,
 'Loss/regularization_loss': 0.030403806,
 'Loss/total_loss': 0.3314003,
 'learning_rate': 0.05788}
I1208 09:57:11.268785 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.27975702,
 'Loss/localization_loss': 0.021239476,
 'Loss/regularization_loss': 0.030403806,
 'Loss/total_loss': 0.3314003,
 'learning_rate': 0.05788}
INFO:tensorflow:Step 1900 per-step time 0.660s
I1208 09:58:17.296120 140351250462528 model_lib_v2.py:705] Step 1900 per-step time 0.660s
INFO:tensorflow:{'Loss/classification_loss': 0.28714797,
 'Loss/localization_loss': 0.015713464,
 'Loss/regularization_loss': 0.030508313,
 'Loss/total_loss': 0.33336973,
 'learning_rate': 0.06104}
I1208 09:58:17.296359 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.28714797,
 'Loss/localization_loss': 0.015713464,
 'Loss/regularization_loss': 0.030508313,
 'Loss/total_loss': 0.33336973,
 'learning_rate': 0.06104}
INFO:tensorflow:Step 2000 per-step time 0.659s
I1208 09:59:23.158999 140351250462528 model_lib_v2.py:705] Step 2000 per-step time 0.659s
INFO:tensorflow:{'Loss/classification_loss': 0.23907833,
 'Loss/localization_loss': 0.014411955,
 'Loss/regularization_loss': 0.030650519,
 'Loss/total_loss': 0.2841408,
 'learning_rate': 0.06420001}
I1208 09:59:23.159236 140351250462528 model_lib_v2.py:708] {'Loss/classification_loss': 0.23907833,
 'Loss/localization_loss': 0.014411955,
 'Loss/regularization_loss': 0.030650519,
 'Loss/total_loss': 0.2841408,
 'learning_rate': 0.06420001}
==EVALUATING THE MODEL==
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1208 09:59:32.020654 139737296000832 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
I1208 09:59:32.021003 139737296000832 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I1208 09:59:32.021114 139737296000832 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I1208 09:59:32.021197 139737296000832 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1208 09:59:32.021312 139737296000832 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
I1208 09:59:32.335326 139737296000832 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1
I1208 09:59:32.335461 139737296000832 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88
I1208 09:59:32.335517 139737296000832 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4
I1208 09:59:32.338977 139737296000832 efficientnet_model.py:143] round_filter input=32 output=32
I1208 09:59:32.370550 139737296000832 efficientnet_model.py:143] round_filter input=32 output=32
I1208 09:59:32.370674 139737296000832 efficientnet_model.py:143] round_filter input=16 output=16
I1208 09:59:32.504283 139737296000832 efficientnet_model.py:143] round_filter input=16 output=16
I1208 09:59:32.504411 139737296000832 efficientnet_model.py:143] round_filter input=24 output=24
I1208 09:59:32.740620 139737296000832 efficientnet_model.py:143] round_filter input=24 output=24
I1208 09:59:32.740749 139737296000832 efficientnet_model.py:143] round_filter input=40 output=40
I1208 09:59:32.975600 139737296000832 efficientnet_model.py:143] round_filter input=40 output=40
I1208 09:59:32.975742 139737296000832 efficientnet_model.py:143] round_filter input=80 output=80
I1208 09:59:33.279637 139737296000832 efficientnet_model.py:143] round_filter input=80 output=80
I1208 09:59:33.279764 139737296000832 efficientnet_model.py:143] round_filter input=112 output=112
I1208 09:59:33.585991 139737296000832 efficientnet_model.py:143] round_filter input=112 output=112
I1208 09:59:33.586144 139737296000832 efficientnet_model.py:143] round_filter input=192 output=192
I1208 09:59:33.960589 139737296000832 efficientnet_model.py:143] round_filter input=192 output=192
I1208 09:59:33.960728 139737296000832 efficientnet_model.py:143] round_filter input=320 output=320
I1208 09:59:34.116117 139737296000832 efficientnet_model.py:143] round_filter input=1280 output=1280
I1208 09:59:34.152706 139737296000832 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
INFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']
I1208 09:59:34.334966 139737296000832 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']
INFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']
I1208 09:59:34.335909 139737296000832 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']
INFO:tensorflow:Number of filenames to read: 13
I1208 09:59:34.335987 139737296000832 dataset_builder.py:80] Number of filenames to read: 13
WARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.
W1208 09:59:34.336077 139737296000832 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.
WARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.
W1208 09:59:34.337679 139737296000832 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
W1208 09:59:34.339113 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W1208 09:59:34.353729 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W1208 09:59:38.131888 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1208 09:59:39.257664 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at /opt/training
I1208 09:59:41.574624 139737296000832 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training
INFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3
I1208 09:59:41.575205 139737296000832 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3
/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn(
I1208 09:59:49.162526 139737296000832 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
I1208 10:00:02.342903 139737296000832 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1208 10:00:07.708581 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Finished eval step 0
I1208 10:00:07.803609 139737296000832 model_lib_v2.py:966] Finished eval step 0
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W1208 10:00:07.938348 139737296000832 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
INFO:tensorflow:Finished eval step 100
I1208 10:00:18.625147 139737296000832 model_lib_v2.py:966] Finished eval step 100
INFO:tensorflow:Finished eval step 200
I1208 10:00:26.505665 139737296000832 model_lib_v2.py:966] Finished eval step 200
INFO:tensorflow:Performing evaluation on 258 images.
I1208 10:00:30.740998 139737296000832 coco_evaluation.py:293] Performing evaluation on 258 images.
INFO:tensorflow:Loading and preparing annotation results...
I1208 10:00:30.745235 139737296000832 coco_tools.py:116] Loading and preparing annotation results...
INFO:tensorflow:DONE (t=0.01s)
I1208 10:00:30.758509 139737296000832 coco_tools.py:138] DONE (t=0.01s)
INFO:tensorflow:Eval metrics at step 2000
I1208 10:00:39.868623 139737296000832 model_lib_v2.py:1015] Eval metrics at step 2000
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.059294
I1208 10:00:39.912153 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.059294
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.160264
I1208 10:00:39.913544 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.160264
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.026080
I1208 10:00:39.914536 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.026080
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.026752
I1208 10:00:39.915489 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.026752
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.263643
I1208 10:00:39.916429 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.263643
INFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.190787
I1208 10:00:39.917424 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.190787
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.018493
I1208 10:00:39.918355 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.018493
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.081050
I1208 10:00:39.919321 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.081050
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.115478
I1208 10:00:39.920262 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.115478
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.062126
I1208 10:00:39.921230 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.062126
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.393135
I1208 10:00:39.922408 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.393135
INFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.563213
I1208 10:00:39.923386 139737296000832 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.563213
INFO:tensorflow:#011+ Loss/localization_loss: 0.023916
I1208 10:00:39.924118 139737296000832 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.023916
INFO:tensorflow:#011+ Loss/classification_loss: 0.489601
I1208 10:00:39.924891 139737296000832 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.489601
INFO:tensorflow:#011+ Loss/regularization_loss: 0.030652
I1208 10:00:39.925620 139737296000832 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.030652
INFO:tensorflow:#011+ Loss/total_loss: 0.544170
I1208 10:00:39.926382 139737296000832 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.544170
INFO:tensorflow:Waiting for new checkpoint at /opt/training
I1208 10:04:41.674097 139737296000832 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training
INFO:tensorflow:Timed-out waiting for a checkpoint.
I1208 10:04:50.685254 139737296000832 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.
creating index...
index created!
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=8.86s).
Accumulating evaluation results...
DONE (t=0.22s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.081
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563
==EXPORTING THE MODEL==
I1208 10:04:54.823199 140687260030784 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1
I1208 10:04:54.823343 140687260030784 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88
I1208 10:04:54.823395 140687260030784 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4
I1208 10:04:54.826918 140687260030784 efficientnet_model.py:143] round_filter input=32 output=32
I1208 10:04:54.857942 140687260030784 efficientnet_model.py:143] round_filter input=32 output=32
I1208 10:04:54.858078 140687260030784 efficientnet_model.py:143] round_filter input=16 output=16
I1208 10:04:54.990369 140687260030784 efficientnet_model.py:143] round_filter input=16 output=16
I1208 10:04:54.990496 140687260030784 efficientnet_model.py:143] round_filter input=24 output=24
I1208 10:04:55.229106 140687260030784 efficientnet_model.py:143] round_filter input=24 output=24
I1208 10:04:55.229234 140687260030784 efficientnet_model.py:143] round_filter input=40 output=40
I1208 10:04:55.462729 140687260030784 efficientnet_model.py:143] round_filter input=40 output=40
I1208 10:04:55.462861 140687260030784 efficientnet_model.py:143] round_filter input=80 output=80
I1208 10:04:55.767267 140687260030784 efficientnet_model.py:143] round_filter input=80 output=80
I1208 10:04:55.767402 140687260030784 efficientnet_model.py:143] round_filter input=112 output=112
I1208 10:04:56.078094 140687260030784 efficientnet_model.py:143] round_filter input=112 output=112
I1208 10:04:56.078222 140687260030784 efficientnet_model.py:143] round_filter input=192 output=192
I1208 10:04:56.457897 140687260030784 efficientnet_model.py:143] round_filter input=192 output=192
I1208 10:04:56.458026 140687260030784 efficientnet_model.py:143] round_filter input=320 output=320
I1208 10:04:56.614890 140687260030784 efficientnet_model.py:143] round_filter input=1280 output=1280
I1208 10:04:56.651339 140687260030784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.map_fn(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))
W1208 10:04:58.488864 140687260030784 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.map_fn(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))
I1208 10:05:02.947331 140687260030784 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
I1208 10:05:12.880000 140687260030784 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
I1208 10:05:16.153475 140687260030784 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_2_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.
I1208 10:05:19.135687 140687260030784 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]
WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7ff34420a190>, because it is not built.
W1208 10:05:21.325298 140687260030784 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7ff34420a190>, because it is not built.
I1208 10:05:51.339723 140687260030784 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets
I1208 10:06:17.286933 140687260030784 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets
I1208 10:06:18.303156 140687260030784 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb
INFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config
I1208 10:06:19.537868 140687260030784 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config
2023-12-08 10:06:21,763 sagemaker-training-toolkit INFO     Reporting training SUCCESS

2023-12-08 10:06:39 Uploading - Uploading generated training model
2023-12-08 10:06:39 Completed - Training job completed
Training seconds: 2024
Billable seconds: 2024